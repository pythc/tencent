# StarRocks NL-to-SQL ç¿»è¯‘é¡¹ç›®

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ—¨åœ¨å®ç°ç¨³å®šçš„è‡ªç„¶è¯­è¨€åˆ° SQL çš„ç¿»è¯‘ç³»ç»Ÿï¼Œä¸“é—¨é’ˆå¯¹ **StarRocks** æ•°æ®åº“æ–¹è¨€ã€‚ç›®æ ‡æ˜¯åœ¨ StarRocks ä¸Šç”Ÿæˆ**å¯æ‰§è¡Œä¸”å£å¾„æ­£ç¡®**çš„ SQL æŸ¥è¯¢ã€‚

### æ ¸å¿ƒè¦æ±‚

- **å¯æ‰§è¡Œæ€§**ï¼šç”Ÿæˆçš„ SQL å¿…é¡»ç¬¦åˆ StarRocks è¯­æ³•è§„èŒƒï¼Œèƒ½å¤ŸæˆåŠŸæ‰§è¡Œ
- **å£å¾„æ­£ç¡®æ€§**ï¼šSQL çš„ä¸šåŠ¡é€»è¾‘å¿…é¡»ç¬¦åˆé¢˜é¢è¦æ±‚ï¼ŒåŒ…æ‹¬å­—æ®µåã€æ—¥æœŸæ ¼å¼ã€ä¸šåŠ¡å£å¾„ç­‰

---

## ğŸ¯ æŠ€æœ¯æ–¹æ¡ˆ

### åŒé˜¶æ®µ QLoRA å¾®è°ƒç­–ç•¥

é‡‡ç”¨**ä¸¤é˜¶æ®µæ¸è¿›å¼è®­ç»ƒ**ç­–ç•¥ï¼Œä»é€šç”¨èƒ½åŠ›åˆ°åŸŸå†…å¯¹é½ï¼š

#### Stage Aï¼šé€šç”¨èƒ½åŠ›è®­ç»ƒï¼ˆSFTï¼‰
- **æ•°æ®é›†**ï¼šCSpiderï¼ˆä¸­æ–‡ SQL æ•°æ®é›†ï¼‰
- **ç›®æ ‡**ï¼šå­¦ä¹ å¤æ‚ SQL ç»“æ„
  - CTEï¼ˆWITH å­å¥ï¼‰
  - å¤šè¡¨ JOIN
  - å­æŸ¥è¯¢
  - çª—å£å‡½æ•°
  - HAVING å­å¥
- **é€‚é…**ï¼šå°† CSpider çš„ SQL é€‚é…ä¸º StarRocks æ–¹è¨€

#### Stage Bï¼šåŸŸå†…å¯¹é½è®­ç»ƒï¼ˆSFT + ORPOï¼‰
- **æ•°æ®é›†**ï¼šå®˜æ–¹ 72 æ¡æ ·æœ¬çš„ç¨‹åºåŒ–å¢å¹¿ï¼ˆæ‰©è‡³ 200-500 æ¡ï¼‰
- **ç›®æ ‡**ï¼šé”å®š StarRocks æ–¹è¨€å’Œä¸šåŠ¡å£å¾„
  - æ—¥æœŸæ ¼å¼ï¼šç»Ÿä¸€ä½¿ç”¨å­—ç¬¦ä¸² `'YYYYMMDD'`
  - ä¸šåŠ¡å£å¾„ï¼šå¦‚ `saccounttype='-100'`ã€`suseridtype in ('qq','wxid')`
  - è¾“å‡ºå­—æ®µåï¼šä¸é¢˜é¢ä¸€è‡´
  - å‡½æ•°é€‚é…ï¼š`COALESCE`ã€`SUBSTR`ã€`LOCATE` ç­‰
- **æ–¹æ³•**ï¼š
  1. **SFT**ï¼šåŸŸå†…æ•°æ®çš„ç›‘ç£å¾®è°ƒ
  2. **ORPO**ï¼ˆå¯é€‰ï¼‰ï¼šä½¿ç”¨ chosen/rejected å¯¹è¿›è¡Œåå¥½ä¼˜åŒ–

### æ•°æ®é…æ¯”

- **CSpider : åŸŸå†…å¢å¹¿ = 60% : 40%**ï¼ˆæŒ‰ token æ•°è®¡ç®—ï¼‰

### æ¨¡å‹ä¸æ¡†æ¶

- **åŸºç¡€æ¨¡å‹**ï¼šQwen/Qwen2.5-14B-Instruct
- **è®­ç»ƒæ¡†æ¶**ï¼šLLaMA-Factory
- **é‡åŒ–æ–¹æ³•**ï¼šQLoRAï¼ˆ4-bit é‡åŒ–ï¼‰
- **LoRA å‚æ•°**ï¼š
  - `lora_rank: 16`
  - `lora_alpha: 32`
  - `lora_dropout: 0.05`
  - `lora_target: all`

---

## ğŸ› ï¸ ç¯å¢ƒæ„å»º

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šLinuxï¼ˆæ¨è Ubuntu 20.04+ï¼‰
- **Python**ï¼š3.10+ï¼ˆæ¨è 3.10 æˆ– 3.12ï¼‰
- **CUDA**ï¼š11.6+ï¼ˆæ¨è 12.2ï¼‰
- **GPU**ï¼šV100 32GB æˆ–æ›´é«˜ï¼ˆQLoRA 4-bit çº¦éœ€ 12GB æ˜¾å­˜ï¼‰

### Python ç¯å¢ƒæ­å»º

#### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
cd /home/ubuntu/workspace/tencent
python3 -m venv .venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate
```

#### 2. å®‰è£… PyTorch

```bash
# æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©ï¼ˆä»¥ CUDA 12.1 ä¸ºä¾‹ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### 3. å®‰è£… LLaMA-Factory

```bash
cd /home/ubuntu/workspace/LLaMA-Factory
pip install -e ".[torch,bitsandbytes]"
```

#### 4. å®‰è£…å…¶ä»–ä¾èµ–

```bash
# å®‰è£… StarRocks æ•°æ®åº“è¿æ¥åº“
pip install PyMySQL

# å®‰è£…å…¶ä»–å¿…è¦åº“
pip install transformers>=4.49.0
pip install peft>=0.14.0
pip install accelerate>=1.3.0
pip install datasets>=2.16.0
pip install trl>=0.8.6
pip install safetensors
pip install sentencepiece
pip install tiktoken
```

#### 5. éªŒè¯å®‰è£…

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import peft; print(f'PEFT: {peft.__version__}')"
```

### ç›®å½•ç»“æ„

```
tencent/
â”œâ”€â”€ final_for_student/          # é¡¹ç›®ä¸»ç›®å½•
â”‚   â”œâ”€â”€ configs/                # è®­ç»ƒé…ç½®æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ stage_a_sft.yaml
â”‚   â”‚   â”œâ”€â”€ stage_b_sft.yaml
â”‚   â”‚   â””â”€â”€ stage_b_orpo.yaml
â”‚   â”œâ”€â”€ data/                   # æ•°æ®ç›®å½•
â”‚   â”‚   â”œâ”€â”€ cspider_train.json  # CSpider è®­ç»ƒæ•°æ®
â”‚   â”‚   â”œâ”€â”€ sft_conversation.json # åŸŸå†… SFT æ•°æ®
â”‚   â”‚   â”œâ”€â”€ final_dataset.json  # æœ€ç»ˆè¯„ä¼°æ•°æ®é›†ï¼ˆ101æ¡ï¼‰
â”‚   â”‚   â”œâ”€â”€ schema.json         # æ•°æ®åº“ schema
â”‚   â”‚   â””â”€â”€ common_knowledge.md # å…¬å…±ä¸šåŠ¡çŸ¥è¯†
â”‚   â”œâ”€â”€ scripts/                # è„šæœ¬ç›®å½•
â”‚   â”‚   â”œâ”€â”€ adapt_sql_to_starrocks.py  # SQL é€‚é…è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ prepare_cspider.py         # CSpider æ•°æ®å‡†å¤‡
â”‚   â”‚   â”œâ”€â”€ prepare_domain_data.py     # åŸŸå†…æ•°æ®å‡†å¤‡
â”‚   â”‚   â”œâ”€â”€ mix_datasets.py            # æ•°æ®é›†æ··åˆ
â”‚   â”‚   â”œâ”€â”€ register_datasets.py      # æ•°æ®é›†æ³¨å†Œ
â”‚   â”‚   â”œâ”€â”€ evaluate.py                # è¯„ä¼°è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ generate_submission.py     # æäº¤ç”Ÿæˆè„šæœ¬
â”‚   â”‚   â””â”€â”€ run_submission.sh          # æäº¤ä¾¿æ·è„šæœ¬
â”‚   â”œâ”€â”€ saves/                   # è®­ç»ƒè¾“å‡ºç›®å½•ï¼ˆåœ¨ LLaMA-Factory ä¸­ï¼‰
â”‚   â””â”€â”€ docs/                    # æ–‡æ¡£ç›®å½•
â”‚       â””â”€â”€ sql_adaptation_rules.md    # SQL é€‚é…è§„åˆ™æ–‡æ¡£
â”œâ”€â”€ LLaMA-Factory/              # LLaMA-Factory æ¡†æ¶
â””â”€â”€ models/                     # æ¨¡å‹ç›®å½•
    â””â”€â”€ Qwen_Qwen2.5-14B-Instruct/
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡

### 1. CSpider æ•°æ®å‡†å¤‡

å°† CSpider åŸå§‹æ•°æ®è½¬æ¢ä¸º LLaMA-Factory çš„ **sharegpt** æ ¼å¼ï¼Œå¹¶åº”ç”¨ StarRocks SQL é€‚é…ã€‚

**æ•°æ®æ ¼å¼è¯´æ˜**ï¼š
- è™½ç„¶ä½¿ç”¨ sharegpt æ ¼å¼ï¼Œä½†æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯**å•è½®å¯¹è¯**ï¼ˆæ¯ä¸ªæ ·æœ¬ï¼šsystem â†’ user â†’ assistantï¼‰
- Sharegpt æ ¼å¼ä¹Ÿæ”¯æŒå•è½®å¯¹è¯ï¼ŒLLaMA-Factory å†…éƒ¨ä¼šå°†å…¶è½¬æ¢ä¸ºç»Ÿä¸€çš„ messages æ ¼å¼
- é€šè¿‡ `tags` é…ç½®å°† `role`/`content` å­—æ®µæ˜ å°„åˆ° LLaMA-Factory çš„å†…éƒ¨æ ¼å¼
- ç†è®ºä¸Šä¹Ÿå¯ä»¥ä½¿ç”¨ alpaca æ ¼å¼ï¼Œä½† sharegpt æ ¼å¼å·²ç»è¶³å¤Ÿä¸”æ›´é€šç”¨

```bash
cd /home/ubuntu/workspace/tencent/final_for_student
source /home/ubuntu/workspace/tencent/.venv/bin/activate

python scripts/prepare_cspider.py \
  --train_json /path/to/CSpider/train.json \
  --gold_sql /path/to/CSpider/train_gold.sql \
  --tables_json /path/to/CSpider/tables.json \
  --output data/cspider_train.json
```

### 2. åŸŸå†…æ•°æ®å‡†å¤‡

å‡†å¤‡åŸŸå†… SFT å’Œ ORPO æ•°æ®ï¼š

```bash
python scripts/prepare_domain_data.py \
  --input data/sft_conversation.json \
  --output_sft data/domain_sft.json \
  --output_orpo data/domain_orpo.json
```

### 3. æ•°æ®é›†æ··åˆ

æŒ‰ token æ¯”ä¾‹æ··åˆ CSpider å’ŒåŸŸå†…æ•°æ®ï¼ˆ60:40ï¼‰ï¼š

```bash
python scripts/mix_datasets.py \
  --cspider_path data/cspider_train.json \
  --domain_path data/domain_sft.json \
  --output data/cspider_domain_mixed.json \
  --tokenizer_path /home/ubuntu/workspace/tencent/models/Qwen_Qwen2.5-14B-Instruct \
  --cspider_ratio 0.6
```

### 4. æ³¨å†Œæ•°æ®é›†åˆ° LLaMA-Factory

```bash
python scripts/register_datasets.py \
  --llama_factory_data_path /home/ubuntu/workspace/LLaMA-Factory/data \
  --custom_datasets_config_path configs/datasets.json
```

---

## ğŸš€ è®­ç»ƒæµç¨‹

### Stage Aï¼šé€šç”¨èƒ½åŠ›è®­ç»ƒï¼ˆSFTï¼‰

```bash
cd /home/ubuntu/workspace/LLaMA-Factory
source /home/ubuntu/workspace/tencent/.venv/bin/activate

llamafactory-cli train /home/ubuntu/workspace/tencent/final_for_student/configs/stage_a_sft.yaml
```

**å…³é”®å‚æ•°ï¼š**
- `cutoff_len: 2048` - åºåˆ—æˆªæ–­é•¿åº¦ï¼ˆæ•°æ®æœ€å¤§é•¿åº¦ 617ï¼‰
- `packing: true` - æ ·æœ¬æ‰“åŒ…ï¼Œå‡å°‘ padding
- `group_by_length: true` - æŒ‰é•¿åº¦åˆ†æ¡¶
- `gradient_accumulation_steps: 32` - æ¢¯åº¦ç´¯ç§¯
- `learning_rate: 1.0e-4` - å­¦ä¹ ç‡
- `num_train_epochs: 1.0` - è®­ç»ƒ 1 ä¸ª epoch

**è¾“å‡ºï¼š** `LLaMA-Factory/saves/stage_a_sft/`

### Stage Bï¼šåŸŸå†…å¯¹é½è®­ç»ƒï¼ˆSFTï¼‰

```bash
llamafactory-cli train /home/ubuntu/workspace/tencent/final_for_student/configs/stage_b_sft.yaml
```

**å…³é”®å‚æ•°ï¼š**
- `adapter_name_or_path: saves/stage_a_sft` - ä» Stage A ç»§ç»­è®­ç»ƒ
- `cutoff_len: 3072` - åŸŸå†…æ•°æ®è¾ƒé•¿ï¼Œä¿æŒ 3072
- `learning_rate: 5.0e-5` - å­¦ä¹ ç‡é™ä½
- `num_train_epochs: 1.0` - è®­ç»ƒ 1 ä¸ª epoch

**è¾“å‡ºï¼š** `LLaMA-Factory/saves/stage_b_sft/`

### Stage Bï¼šåŸŸå†…å¯¹é½è®­ç»ƒï¼ˆORPOï¼Œå¯é€‰ï¼‰

```bash
llamafactory-cli train /home/ubuntu/workspace/tencent/final_for_student/configs/stage_b_orpo.yaml
```

**å…³é”®å‚æ•°ï¼š**
- `adapter_name_or_path: saves/stage_b_sft` - ä» Stage B SFT ç»§ç»­è®­ç»ƒ
- `stage: dpo` - ä½¿ç”¨ DPO stage
- `pref_loss: orpo` - ä½¿ç”¨ ORPO loss
- `pref_beta: 0.1` - ORPO beta å‚æ•°
- `packing: false` - ORPO é€šå¸¸ä¸å¯ç”¨ packing
- `learning_rate: 1.0e-5` - è¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡
- `num_train_epochs: 1.5` - è®­ç»ƒ 1.5 ä¸ª epochï¼ˆå¯åœ¨ 1.0 åç»§ç»­ï¼‰

**è¾“å‡ºï¼š** `LLaMA-Factory/saves/stage_b_orpo/`

**ç»­è®­ï¼š** é‡å¤æ‰§è¡Œä¸Šè¿°å‘½ä»¤ä¼šè‡ªåŠ¨ä»æœ€æ–° checkpoint ç»§ç»­è®­ç»ƒï¼ˆ`overwrite_output_dir: false`ï¼Œ`resume_from_checkpoint: null`ï¼‰

---

## ğŸ“ˆ è¯„ä¼°

### è¯„ä¼°è„šæœ¬

ä½¿ç”¨è¯„ä¼°è„šæœ¬æµ‹è¯•æ¨¡å‹çš„å¯æ‰§è¡Œç‡å’Œæ­£ç¡®ç‡ï¼š

```bash
cd /home/ubuntu/workspace/tencent/final_for_student
source /home/ubuntu/workspace/tencent/.venv/bin/activate

python scripts/evaluate.py \
  --base_model_path /home/ubuntu/workspace/tencent/models/Qwen_Qwen2.5-14B-Instruct \
  --adapter_path /home/ubuntu/workspace/LLaMA-Factory/saves/stage_b_orpo/checkpoint-12 \
  --samples_file data/success_samples.jsonl \
  --schema_file data/schema.json \
  --db_host 127.0.0.1 \
  --db_port 9030 \
  --db_user root \
  --db_password "" \
  --db_name testDB \
  --output evaluation_result.json \
  --save_predictions predictions.json
```

### è¯„ä¼°æŒ‡æ ‡

- **å¯æ‰§è¡Œç‡**ï¼šç”Ÿæˆçš„ SQL èƒ½å¤ŸæˆåŠŸæ‰§è¡Œçš„ç™¾åˆ†æ¯”
- **æ­£ç¡®ç‡**ï¼šæ‰§è¡Œç»“æœä¸é¢„æœŸç»“æœåŒ¹é…çš„ç™¾åˆ†æ¯”ï¼ˆéœ€è¦æä¾› ground truthï¼‰

---

## ğŸ“¤ æäº¤

### ç”Ÿæˆæäº¤æ–‡ä»¶

ä½¿ç”¨æäº¤è„šæœ¬ç”Ÿæˆæ¯”èµ›æäº¤æ–‡ä»¶ï¼š

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼ˆè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–° checkpointï¼‰
bash scripts/run_submission.sh

# æ–¹æ³•2ï¼šæŒ‡å®š checkpoint ç¼–å·
bash scripts/run_submission.sh 12

# æ–¹æ³•3ï¼šç›´æ¥ä½¿ç”¨ Python è„šæœ¬
python scripts/generate_submission.py \
  --base_model_path /home/ubuntu/workspace/tencent/models/Qwen_Qwen2.5-14B-Instruct \
  --adapter_path /home/ubuntu/workspace/LLaMA-Factory/saves/stage_b_orpo/checkpoint-12 \
  --samples_file data/final_dataset.json \
  --schema_file data/schema.json \
  --knowledge_file data/common_knowledge.md \
  --output submission.json
```

**è¾“å‡ºæ ¼å¼ï¼š**

```json
[
  {
    "sql_id": "sql_1",
    "sql": "SELECT ..."
  },
  {
    "sql_id": "sql_2",
    "sql": "SELECT ..."
  },
  ...
]
```

### æ³¨æ„äº‹é¡¹

1. **æ•°æ®å‡†å¤‡**ï¼šç¡®ä¿å·²é€šè¿‡ `sql_exe.py` æ‰§è¡Œ `insert_sql.json` å®Œæˆæ•°æ®æ’å…¥
2. **é¢˜ç›®æ•°é‡**ï¼š`final_dataset.json` åŒ…å« 101 æ¡é¢˜ç›®ï¼Œæ¯”èµ›ç³»ç»Ÿä¼šè‡ªåŠ¨ç­›é€‰ 86 é“
3. **æäº¤æ ¼å¼**ï¼šè¾“å‡ºæ–‡ä»¶å¿…é¡»åŒ…å«æ‰€æœ‰é¢˜ç›®çš„ `sql_id` å’Œ `sql` å­—æ®µ

---

## âš™ï¸ è®­ç»ƒåŠ é€ŸæŠ€å·§

### å·²åº”ç”¨çš„ä¼˜åŒ–

1. **åºåˆ—æˆªæ–­**ï¼š`cutoff_len` ä» 3072 é™è‡³ 2048ï¼ˆStage Aï¼‰
2. **æ ·æœ¬æ‰“åŒ…**ï¼š`packing: true` + `group_by_length: true`
3. **æ¢¯åº¦ç´¯ç§¯**ï¼š`gradient_accumulation_steps: 32`ï¼ˆStage Aï¼‰
4. **å‡å°‘ I/O**ï¼š`save_steps: 1000`ï¼Œ`eval_steps: 1000`ï¼Œ`logging_steps: 100`
5. **ç¼“å­˜ä¼˜åŒ–**ï¼š`overwrite_cache: false`ï¼Œä½¿ç”¨é¢„å¤„ç†ç¼“å­˜

### è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

- é™ä½ `lora_rank` ä» 16 åˆ° 8ï¼ˆé€Ÿåº¦æå‡ï¼Œæ•ˆæœå¯èƒ½å°å¹…ä¸‹é™ï¼‰
- åªè®­ç»ƒæ³¨æ„åŠ›å±‚ï¼š`lora_target: q_proj,k_proj,v_proj,o_proj`
- å‡å°‘è®­ç»ƒè½®æ•°ï¼šå…ˆç”¨ 0.5-1 epoch å¾—åˆ° baselineï¼Œå†ç”¨ ORPO ç²¾ä¿®

---

## ğŸ“ SQL é€‚é…è§„åˆ™

StarRocks æ–¹è¨€çš„ SQL é€‚é…è§„åˆ™è¯¦è§ï¼š`docs/sql_adaptation_rules.md`

**å…³é”®è§„åˆ™ï¼š**
- **æ—¥æœŸæ ¼å¼**ï¼šç»Ÿä¸€ä½¿ç”¨å­—ç¬¦ä¸² `'YYYYMMDD'`
- **ç©ºå€¼å¤„ç†**ï¼šä½¿ç”¨ `COALESCE(x, y)`
- **å­—ç¬¦ä¸²å‡½æ•°**ï¼šä½¿ç”¨ `SUBSTR(s, pos, len)` å’Œ `LOCATE(substr, s)`
- **ç¦ç”¨ FULL OUTER JOIN**ï¼šéœ€æ”¹å†™ä¸º `LEFT JOIN ... UNION ALL ...`
- **CTE**ï¼šä¼˜å…ˆä½¿ç”¨ `WITH` å­å¥
- **åˆ«å**ï¼šç»Ÿä¸€ä½¿ç”¨å°å†™è›‡å½¢å‘½åï¼ˆ`snake_case`ï¼‰

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. è®­ç»ƒä¸­æ–­åå¦‚ä½•ç»­è®­ï¼Ÿ

é‡å¤æ‰§è¡Œç›¸åŒçš„è®­ç»ƒå‘½ä»¤å³å¯ï¼ŒLLaMA-Factory ä¼šè‡ªåŠ¨ä»æœ€æ–° checkpoint ç»§ç»­ï¼ˆ`resume_from_checkpoint: null`ï¼‰ã€‚

### 2. å¦‚ä½•é€‰æ‹© checkpointï¼Ÿ

è¯„ä¼°ä¸åŒ checkpoint çš„æ€§èƒ½ï¼Œé€‰æ‹©å¯æ‰§è¡Œç‡å’Œæ­£ç¡®ç‡æœ€é«˜çš„ã€‚

### 3. æäº¤è„šæœ¬ä¸­æ–­åå¦‚ä½•ç»§ç»­ï¼Ÿ

**å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ **ï¼Œå»ºè®®ï¼š
- ä½¿ç”¨ `nohup` åå°è¿è¡Œ
- æˆ–ä½¿ç”¨ `screen`/`tmux` ä¼šè¯
- æˆ–åˆ†æ‰¹å¤„ç†ï¼ˆä½¿ç”¨ `--max_samples` å‚æ•°ï¼‰

### 4. æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

- é™ä½ `cutoff_len`
- é™ä½ `gradient_accumulation_steps`ï¼ˆä½†éœ€è¦ç›¸åº”æé«˜ `learning_rate`ï¼‰
- é™ä½ `lora_rank`

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [LLaMA-Factory æ–‡æ¡£](https://github.com/hiyouga/LLaMA-Factory)
- [Qwen2.5 æ¨¡å‹æ–‡æ¡£](https://github.com/QwenLM/Qwen2.5)
- [StarRocks SQL å‚è€ƒ](https://docs.starrocks.io/docs/sql-reference/sql-statements/)

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸å…³å¼€æºè®¸å¯è¯ã€‚
